version: '3.8'

services:
  # Nginx Load Balancer & SSL Termination
  nginx:
    image: nginx:1.25-alpine
    container_name: finclick-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - frontend-1
      - frontend-2
      - api-gateway-1
      - api-gateway-2
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'

  # Frontend - React.js (Load Balanced)
  frontend-1:
    build:
      context: ./frontend
      dockerfile: Dockerfile.production
      target: production
    container_name: finclick-frontend-1
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=https://api.finclick.ai
      - REACT_APP_ENVIRONMENT=production
      - REACT_APP_VERSION=${APP_VERSION:-1.0.0}
    volumes:
      - frontend_build:/usr/share/nginx/html:ro
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  frontend-2:
    build:
      context: ./frontend
      dockerfile: Dockerfile.production
      target: production
    container_name: finclick-frontend-2
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=https://api.finclick.ai
      - REACT_APP_ENVIRONMENT=production
      - REACT_APP_VERSION=${APP_VERSION:-1.0.0}
    volumes:
      - frontend_build:/usr/share/nginx/html:ro
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # API Gateway (Load Balanced)
  api-gateway-1:
    build:
      context: ./backend/api-gateway
      dockerfile: Dockerfile.production
    container_name: finclick-api-gateway-1
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=8000
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_EXPIRES_IN=7d
      - RATE_LIMIT_MAX=1000
      - RATE_LIMIT_WINDOW=15
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  api-gateway-2:
    build:
      context: ./backend/api-gateway
      dockerfile: Dockerfile.production
    container_name: finclick-api-gateway-2
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=8000
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_EXPIRES_IN=7d
      - RATE_LIMIT_MAX=1000
      - RATE_LIMIT_WINDOW=15
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # Authentication Service (High Availability)
  auth-service-1:
    build:
      context: ./backend/auth-service
      dockerfile: Dockerfile.production
    container_name: finclick-auth-1
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis-master:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - BCRYPT_ROUNDS=12
      - SESSION_TIMEOUT=3600
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  auth-service-2:
    build:
      context: ./backend/auth-service
      dockerfile: Dockerfile.production
    container_name: finclick-auth-2
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis-master:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - BCRYPT_ROUNDS=12
      - SESSION_TIMEOUT=3600
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # User Service
  user-service:
    build:
      context: ./backend/user-service
      dockerfile: Dockerfile.production
    container_name: finclick-user-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis-master:6379
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Analysis Service
  analysis-service:
    build:
      context: ./backend/analysis-service
      dockerfile: Dockerfile.production
    container_name: finclick-analysis-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
    depends_on:
      postgres-master:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # File Service
  file-service:
    build:
      context: ./backend/file-service
      dockerfile: Dockerfile.production
    container_name: finclick-file-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - AWS_REGION=${AWS_REGION}
    volumes:
      - file_uploads:/app/uploads
    depends_on:
      postgres-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Reporting Service
  reporting-service:
    build:
      context: ./backend/reporting-service
      dockerfile: Dockerfile.production
    container_name: finclick-reporting-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
    volumes:
      - ./reports-templates:/app/templates:ro
      - report_cache:/app/cache
    depends_on:
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # Notification Service
  notification-service:
    build:
      context: ./backend/notification-service
      dockerfile: Dockerfile.production
    container_name: finclick-notification-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis-master:6379
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - SMTP_SECURE=true
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Subscription Service
  subscription-service:
    build:
      context: ./backend/subscription-service
      dockerfile: Dockerfile.production
    container_name: finclick-subscription-service
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - PAYPAL_CLIENT_ID=${PAYPAL_CLIENT_ID}
      - PAYPAL_CLIENT_SECRET=${PAYPAL_CLIENT_SECRET}
      - PAYPAL_MODE=live
    depends_on:
      postgres-master:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # AI Agents Orchestrator
  ai-orchestrator:
    build:
      context: ./ai-agents
      dockerfile: Dockerfile.production
    container_name: finclick-ai-orchestrator
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/${POSTGRES_DB}
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-cluster:5672/
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - FMP_API_KEY=${FMP_API_KEY}
      - AI_RATE_LIMIT=100
      - AI_TIMEOUT=30000
    depends_on:
      postgres-master:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      rabbitmq-cluster:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  # Financial Analysis Engine
  financial-engine:
    build:
      context: ./financial-engine
      dockerfile: Dockerfile.production
    container_name: finclick-financial-engine
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-cluster:5672/
      - FMP_API_KEY=${FMP_API_KEY}
      - ALPHA_VANTAGE_API_KEY=${ALPHA_VANTAGE_API_KEY}
      - QUANDL_API_KEY=${QUANDL_API_KEY}
    depends_on:
      mongo-primary:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      rabbitmq-cluster:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  # Celery Workers for Analysis (Scaled)
  celery-worker-1:
    build:
      context: ./financial-engine
      dockerfile: Dockerfile.production
    container_name: finclick-celery-worker-1
    restart: unless-stopped
    command: celery -A financial_engine.celery worker --loglevel=info --concurrency=4 --queues=analysis,reports
    environment:
      - NODE_ENV=production
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-cluster:5672/
      - CELERY_WORKER_HIJACK_ROOT_LOGGER=false
      - CELERY_WORKER_LOG_COLOR=false
    depends_on:
      redis-master:
        condition: service_healthy
      rabbitmq-cluster:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "celery", "-A", "financial_engine.celery", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  celery-worker-2:
    build:
      context: ./financial-engine
      dockerfile: Dockerfile.production
    container_name: finclick-celery-worker-2
    restart: unless-stopped
    command: celery -A financial_engine.celery worker --loglevel=info --concurrency=4 --queues=notifications,emails
    environment:
      - NODE_ENV=production
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq-cluster:5672/
      - CELERY_WORKER_HIJACK_ROOT_LOGGER=false
      - CELERY_WORKER_LOG_COLOR=false
    depends_on:
      redis-master:
        condition: service_healthy
      rabbitmq-cluster:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    healthcheck:
      test: ["CMD", "celery", "-A", "financial_engine.celery", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # Celery Beat Scheduler
  celery-beat:
    build:
      context: ./financial-engine
      dockerfile: Dockerfile.production
    container_name: finclick-celery-beat
    restart: unless-stopped
    command: celery -A financial_engine.celery beat --loglevel=info --pidfile=/tmp/celerybeat.pid
    environment:
      - NODE_ENV=production
      - MONGODB_URL=mongodb://mongo-primary:27017/${MONGO_DB}
      - REDIS_URL=redis://redis-master:6379
      - CELERY_BEAT_SCHEDULE_FILENAME=/app/celerybeat-schedule
    volumes:
      - celery_beat_data:/app
    depends_on:
      redis-master:
        condition: service_healthy
      mongo-primary:
        condition: service_healthy
    networks:
      - backend
      - database
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.2'

  # PostgreSQL Master-Slave Setup
  postgres-master:
    image: postgres:15-alpine
    container_name: finclick-postgres-master
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_REPLICATION_USER=${POSTGRES_REPLICATION_USER}
      - POSTGRES_REPLICATION_PASSWORD=${POSTGRES_REPLICATION_PASSWORD}
      - POSTGRES_INITDB_ARGS=--auth-host=md5
    command: |
      postgres
      -c wal_level=replica
      -c max_wal_senders=3
      -c max_replication_slots=3
      -c hot_standby=on
      -c shared_preload_libraries=pg_stat_statements
      -c pg_stat_statements.track=all
      -c log_statement=all
      -c log_min_duration_statement=1000
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./database/sql:/docker-entrypoint-initdb.d:ro
      - ./database/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - postgres_logs:/var/log/postgresql
    networks:
      - database
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  postgres-slave:
    image: postgres:15-alpine
    container_name: finclick-postgres-slave
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGUSER=${POSTGRES_REPLICATION_USER}
      - POSTGRES_MASTER_SERVICE=postgres-master
    command: |
      bash -c "
      if [ ! -s /var/lib/postgresql/data/PG_VERSION ]; then
        pg_basebackup -h postgres-master -D /var/lib/postgresql/data -U ${POSTGRES_REPLICATION_USER} -v -P -W
        echo 'standby_mode = on' >> /var/lib/postgresql/data/recovery.conf
        echo 'primary_conninfo = host=postgres-master port=5432 user=${POSTGRES_REPLICATION_USER}' >> /var/lib/postgresql/data/recovery.conf
      fi
      postgres -c hot_standby=on"
    volumes:
      - postgres_slave_data:/var/lib/postgresql/data
    depends_on:
      postgres-master:
        condition: service_healthy
    networks:
      - database
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # MongoDB Replica Set
  mongo-primary:
    image: mongo:6.0
    container_name: finclick-mongo-primary
    restart: unless-stopped
    command: mongod --replSet finclick-rs --bind_ip_all --auth
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USER}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_DB}
    volumes:
      - mongo_primary_data:/data/db
      - mongo_config:/data/configdb
      - ./database/mongo/init-replica.js:/docker-entrypoint-initdb.d/init-replica.js:ro
      - mongo_logs:/var/log/mongodb
    networks:
      - database
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  mongo-secondary:
    image: mongo:6.0
    container_name: finclick-mongo-secondary
    restart: unless-stopped
    command: mongod --replSet finclick-rs --bind_ip_all --auth
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USER}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD}
    volumes:
      - mongo_secondary_data:/data/db
    depends_on:
      mongo-primary:
        condition: service_healthy
    networks:
      - database
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # Redis Cluster
  redis-master:
    image: redis:7-alpine
    container_name: finclick-redis-master
    restart: unless-stopped
    command: redis-server --appendonly yes --replica-announce-ip redis-master --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_master_data:/data
      - ./database/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - database
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  redis-slave:
    image: redis:7-alpine
    container_name: finclick-redis-slave
    restart: unless-stopped
    command: redis-server --appendonly yes --slaveof redis-master 6379 --replica-announce-ip redis-slave
    volumes:
      - redis_slave_data:/data
    depends_on:
      redis-master:
        condition: service_healthy
    networks:
      - database
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # RabbitMQ Cluster
  rabbitmq-cluster:
    image: rabbitmq:3-management-alpine
    container_name: finclick-rabbitmq-cluster
    restart: unless-stopped
    hostname: rabbitmq-cluster
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
      - RABBITMQ_VM_MEMORY_HIGH_WATERMARK=0.7
      - RABBITMQ_DISK_FREE_LIMIT=2GB
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./database/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      - ./database/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json:ro
    networks:
      - database
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: finclick-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    networks:
      - monitoring
      - backend
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:10.0.0
    container_name: finclick-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_SECURITY_SECRET_KEY=${GRAFANA_SECRET_KEY}
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
      - GF_RENDERING_SERVER_URL=http://grafana-renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - monitoring
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Grafana Image Renderer
  grafana-renderer:
    image: grafana/grafana-image-renderer:3.8.0
    container_name: finclick-grafana-renderer
    restart: unless-stopped
    environment:
      - ENABLE_METRICS=true
      - HTTP_PORT=8081
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # ELK Stack - Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.0
    container_name: finclick-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./monitoring/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "curl", "-u", "elastic:${ELASTIC_PASSWORD}", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'

  # ELK Stack - Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.9.0
    container_name: finclick-logstash
    restart: unless-stopped
    environment:
      - LS_JAVA_OPTS=-Xms512m -Xmx512m
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./monitoring/logstash/config:/usr/share/logstash/config:ro
      - logstash_data:/usr/share/logstash/data
      - nginx_logs:/var/log/nginx:ro
      - postgres_logs:/var/log/postgresql:ro
      - mongo_logs:/var/log/mongodb:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9600/_node/stats"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # ELK Stack - Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.0
    container_name: finclick-kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=${ELASTIC_PASSWORD}
      - SERVER_NAME=kibana.finclick.ai
    volumes:
      - kibana_data:/usr/share/kibana/data
      - ./monitoring/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'

  # AlertManager
  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: finclick-alertmanager
    restart: unless-stopped
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=https://alerts.finclick.ai'
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    depends_on:
      - prometheus
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.2'

  # Backup Service
  backup-service:
    build:
      context: ./scripts/backup
      dockerfile: Dockerfile
    container_name: finclick-backup-service
    restart: unless-stopped
    environment:
      - POSTGRES_HOST=postgres-master
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - MONGO_HOST=mongo-primary
      - MONGO_DB=${MONGO_DB}
      - MONGO_USER=${MONGO_ROOT_USER}
      - MONGO_PASSWORD=${MONGO_ROOT_PASSWORD}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_BUCKET=${AWS_BACKUP_BUCKET}
      - BACKUP_SCHEDULE=0 2 * * *
    volumes:
      - backup_data:/backups
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - postgres-master
      - mongo-primary
    networks:
      - database
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

volumes:
  # Application Data
  frontend_build:
  file_uploads:
  report_cache:
  celery_beat_data:

  # Database Data
  postgres_master_data:
  postgres_slave_data:
  mongo_primary_data:
  mongo_secondary_data:
  mongo_config:
  redis_master_data:
  redis_slave_data:
  rabbitmq_data:

  # Monitoring Data
  prometheus_data:
  grafana_data:
  elasticsearch_data:
  logstash_data:
  kibana_data:
  alertmanager_data:

  # Logs
  nginx_logs:
  postgres_logs:
  mongo_logs:

  # Backup Data
  backup_data:

networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.1.0/24
  backend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.2.0/24
  database:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.3.0/24
  monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.4.0/24

# Security and Performance Settings
x-common-variables: &common-variables
  TZ: UTC
  LANG: en_US.UTF-8
  LC_ALL: en_US.UTF-8

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "5"
    labels: "service,version"

x-security: &security-opts
  security_opt:
    - no-new-privileges:true
  read_only: false
  user: "1000:1000"

configs:
  nginx_config:
    file: ./nginx/nginx.conf
  prometheus_config:
    file: ./monitoring/prometheus/prometheus.yml
  grafana_config:
    file: ./monitoring/grafana/grafana.ini

secrets:
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  postgres_password:
    file: ./secrets/postgres_password.txt
  mongo_password:
    file: ./secrets/mongo_password.txt
  redis_password:
    file: ./secrets/redis_password.txt